{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv8 Finetuning for Object Detection and Bounding Boxes Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we fine-tuned a YOLO model for object detection using a custom training dataset, then used the fine-tuned model to make predictions on the test set and generate a submission file for Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 0: IMPORTING NEEDED LIBRARIES\n",
    "\n",
    "%pip install -q ultralytics\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "# use GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 1: DATA PREPARATION\n",
    "\n",
    "# paths\n",
    "train_csv = \"./train.csv\"\n",
    "image_root = \"./input/data-bounty-6-product-object-detection\" # path to the train dataset\n",
    "output_dir = \"./output/yolo_dataset\"  # path to save the YOLO dataset\n",
    "train_images_dir = f\"{output_dir}/images/train\"\n",
    "train_labels_dir = f\"{output_dir}/labels/train\"\n",
    "os.makedirs(train_images_dir, exist_ok=True)\n",
    "os.makedirs(train_labels_dir, exist_ok=True)\n",
    "\n",
    "# load train\n",
    "df = pd.read_csv(train_csv)\n",
    "\n",
    "# encode classes\n",
    "all_classes = []\n",
    "for row in df['prediction_string']:\n",
    "    parts = row.split()\n",
    "    all_classes.extend(parts[::6])\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(all_classes)\n",
    "class2id = {name: idx for idx, name in enumerate(label_encoder.classes_)}\n",
    "id2class = {idx: name for name, idx in class2id.items()}\n",
    "\n",
    "# save class names\n",
    "class_names_path = f\"{output_dir}/class_list.txt\"\n",
    "with open(class_names_path, \"w\") as f:\n",
    "    f.write(\"\\n\".join(label_encoder.classes_))\n",
    "\n",
    "# convert XYXY to YOLO format\n",
    "def convert_bbox(x1, y1, x2, y2, img_w, img_h):\n",
    "    x = (x1 + x2) / 2 / img_w\n",
    "    y = (y1 + y2) / 2 / img_h\n",
    "    w = (x2 - x1) / img_w\n",
    "    h = (y2 - y1) / img_h\n",
    "    return x, y, w, h\n",
    "\n",
    "# create YOLO labels\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    image_id = row[\"image_id\"]\n",
    "    image_path = f\"{image_root}/Train/JPEGImages/{image_id}.jpg\"\n",
    "    label_path = f\"{train_labels_dir}/{image_id}.txt\"\n",
    "    os.system(f\"cp {image_path} {train_images_dir}/{image_id}.jpg\")\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    with open(label_path, \"w\") as f:\n",
    "        items = row[\"prediction_string\"].split()\n",
    "        for i in range(0, len(items), 6):\n",
    "            class_name = items[i]\n",
    "            x1, y1, x2, y2 = map(int, items[i+2:i+6])\n",
    "            class_id = class2id[class_name]\n",
    "            x, y, bw, bh = convert_bbox(x1, y1, x2, y2, w, h)\n",
    "            f.write(f\"{class_id} {x:.6f} {y:.6f} {bw:.6f} {bh:.6f}\\n\")\n",
    "\n",
    "# create YOLOv8 data.yaml\n",
    "data_yaml = {\n",
    "    \"train\": train_images_dir,\n",
    "    \"val\": train_images_dir,\n",
    "    \"nc\": len(label_encoder.classes_),\n",
    "    \"names\": [str(name) for name in label_encoder.classes_.tolist()]  # <- fix here\n",
    "}\n",
    "\n",
    "data_yaml_path = f\"{output_dir}/data.yaml\"\n",
    "with open(data_yaml_path, \"w\") as f:\n",
    "    yaml.dump(data_yaml, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T05:33:24.956384Z",
     "iopub.status.busy": "2025-04-26T05:33:24.955752Z",
     "iopub.status.idle": "2025-04-26T06:16:36.871231Z",
     "shell.execute_reply": "2025-04-26T06:16:36.870449Z",
     "shell.execute_reply.started": "2025-04-26T05:33:24.956351Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m984.0/984.0 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\n",
      "pylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mCreating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 3695/3796 [01:13<00:02, 50.27it/s]sh: 1: Syntax error: \"(\" unexpected\n",
      "100%|██████████| 3796/3796 [01:16<00:00, 49.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.116 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/input/yolo/other/default/1/best.pt, data=/kaggle/working/yolo_dataset/data.yaml, epochs=5, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=cuda, workers=2, project=/kaggle/working/, name=yolo_finetuned, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=/kaggle/working/yolo_finetuned\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 24.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8826787  ultralytics.nn.modules.head.Detect           [113, [320, 640, 640]]        \n",
      "Model summary: 209 layers, 68,261,427 parameters, 68,261,411 gradients, 258.7 GFLOPs\n",
      "\n",
      "Transferred 595/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.35M/5.35M [00:00<00:00, 108MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2539.0±1755.1 MB/s, size: 350.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/yolo_dataset/labels/train... 3795 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3795/3795 [00:02<00:00, 1512.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/yolo_dataset/images/train/XYGOC20200805142211123-1.jpg: 2 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/yolo_dataset/labels/train.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 3490.3±1561.8 MB/s, size: 360.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/yolo_dataset/labels/train.cache... 3795 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3795/3795 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/yolo_dataset/images/train/XYGOC20200805142211123-1.jpg: 2 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /kaggle/working/yolo_finetuned/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=8.5e-05, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 2 dataloader workers\n",
      "Logging results to \u001b[1m/kaggle/working/yolo_finetuned\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/5      6.68G     0.3102     0.1987     0.8285         42        640: 100%|██████████| 475/475 [05:44<00:00,  1.38it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 238/238 [01:47<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3795      18992      0.996      0.996      0.995      0.981\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/5      7.25G     0.2803     0.1759     0.8229         57        640: 100%|██████████| 475/475 [05:52<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 238/238 [01:46<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3795      18992      0.994      0.998      0.995      0.982\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/5      7.27G     0.2821     0.1726     0.8241          2        640: 100%|██████████| 475/475 [05:50<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 238/238 [01:46<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3795      18992      0.997      0.997      0.995      0.983\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        4/5      7.26G     0.2732     0.1733     0.8203         55        640: 100%|██████████| 475/475 [05:49<00:00,  1.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 238/238 [01:46<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3795      18992      0.997      0.998      0.995      0.983\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        5/5      7.31G     0.2709     0.1659     0.8218         54        640: 100%|██████████| 475/475 [05:51<00:00,  1.35it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 238/238 [01:46<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3795      18992      0.998      0.998      0.995      0.985\n",
      "\n",
      "5 epochs completed in 0.638 hours.\n",
      "Optimizer stripped from /kaggle/working/yolo_finetuned/weights/last.pt, 136.9MB\n",
      "Optimizer stripped from /kaggle/working/yolo_finetuned/weights/best.pt, 136.9MB\n",
      "\n",
      "Validating /kaggle/working/yolo_finetuned/weights/best.pt...\n",
      "Ultralytics 8.3.116 🚀 Python-3.11.11 torch-2.5.1+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
      "Model summary (fused): 112 layers, 68,232,387 parameters, 0 gradients, 258.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 238/238 [01:46<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3795      18992      0.998      0.998      0.995      0.985\n",
      "                 3+2-2         44        126      0.998          1      0.995      0.975\n",
      "                 3jia2         46        124          1      0.997      0.995       0.98\n",
      "              aerbeisi         22         38      0.997          1      0.995      0.988\n",
      "                anmuxi         70        107      0.999      0.991      0.995      0.972\n",
      "                aoliao         56        613          1      0.995      0.995      0.942\n",
      "                 asamu         88        246          1          1      0.995      0.991\n",
      "                baicha         47        107      0.987          1      0.992      0.981\n",
      "            baishikele         70        160          1      0.994      0.995      0.984\n",
      "          baishikele-2         44         75      0.995          1      0.995      0.986\n",
      "            baokuangli         59        179      0.999          1      0.995       0.99\n",
      "           binghongcha         77        160      0.999          1      0.995      0.977\n",
      "       bingqilinniunai         56        120      0.999          1      0.995      0.973\n",
      "         bingtangxueli         55        120      0.999          1      0.995       0.99\n",
      "                buding         14        103      0.999          1      0.995      0.993\n",
      "                chacui         83        188          1          1      0.995      0.994\n",
      "                chapai         80        194      0.999       0.99      0.995      0.991\n",
      "               chapai2         96        255      0.996      0.997      0.995      0.994\n",
      "              damaicha         69        134      0.998          1      0.995      0.986\n",
      "           daofandian1         40         40      0.996          1      0.995      0.991\n",
      "           daofandian2         41         41      0.996          1      0.995      0.995\n",
      "           daofandian3         39         39      0.997          1      0.995      0.992\n",
      "           daofandian4         41         41      0.998          1      0.995      0.995\n",
      "              dongpeng         67        152      0.999          1      0.995      0.991\n",
      "            dongpeng-b         74        124      0.999          1      0.995      0.976\n",
      "                 fenda        116        358      0.999          1      0.995      0.988\n",
      "               gudasao         30         45      0.997          1      0.995      0.995\n",
      "            guolicheng         78        258          1          1      0.995      0.988\n",
      "           guolicheng2         23         40      0.998          1      0.995      0.991\n",
      "                haitai         45         82      0.999          1      0.995      0.991\n",
      "            haochidian         38         90      0.989      0.968      0.994      0.948\n",
      "              haoliyou        150        216          1          1      0.995      0.985\n",
      "              heweidao         80        170      0.999          1      0.995      0.985\n",
      "             heweidao2         39         72      0.998          1      0.995      0.991\n",
      "             heweidao3         46         79      0.995          1      0.995      0.993\n",
      "               hongniu         36         93      0.998          1      0.995      0.994\n",
      "              hongniu2        102        249          1          1      0.995      0.993\n",
      "        hongshaoniurou         76        158      0.999          1      0.995      0.994\n",
      "              jianjiao         45        117      0.999          1      0.995      0.981\n",
      "             jianlibao         64        109      0.999          1      0.995      0.988\n",
      "               jindian        131        199          1      0.998      0.995      0.977\n",
      "                 kafei        182        704          1          1      0.995      0.965\n",
      "            kaomo_gali         22         64      0.998          1      0.995      0.986\n",
      "         kaomo_jiaoyan         14         48      0.997          1      0.995      0.985\n",
      "         kaomo_shaokao         22         65      0.998          1      0.995      0.968\n",
      "        kaomo_xiangcon         13         51      0.997          1      0.995       0.99\n",
      "                kebike         67        131      0.999          1      0.995      0.988\n",
      "                  kele        160        657          1      0.997      0.995      0.989\n",
      "                kele-b         53         99      0.999          1      0.995      0.983\n",
      "              kele-b-2         27         53      0.996          1      0.995      0.978\n",
      "         laotansuancai         85        140      0.999          1      0.995      0.994\n",
      "              liaomian         36         81      0.998          1      0.995      0.993\n",
      "             libaojian         55        105          1      0.983      0.995      0.977\n",
      "            lingdukele        147        608          1          1      0.995      0.977\n",
      "          lingdukele-b         29         48      0.998          1      0.995      0.982\n",
      "              liziyuan        118        253          1      0.995      0.995      0.987\n",
      "           lujiaoxiang         21         49      0.998          1      0.995       0.99\n",
      "             lujikafei         96        193          1          1      0.995      0.975\n",
      "         luxiangniurou         48         83      0.997          1      0.995      0.995\n",
      "               maidong         91        283          1          1      0.995      0.985\n",
      "        mangguoxiaolao        126        347      0.999          1      0.995      0.993\n",
      "               meiniye         72         96      0.996          1      0.995       0.98\n",
      "               mengniu         51         81      0.999          1      0.995      0.971\n",
      "         mengniuzaocan         48         61          1       0.99      0.995      0.987\n",
      "           moliqingcha         90        277      0.999      0.996      0.995      0.985\n",
      "                   nfc         45        100      0.999          1      0.995      0.989\n",
      "              niudufen         25         29      0.996          1      0.995      0.982\n",
      "                niunai         67        437          1          1      0.995      0.977\n",
      "        nongfushanquan         73        190      0.999          1      0.995      0.977\n",
      "       qingdaowangzi-1        109        279          1          1      0.995      0.984\n",
      "       qingdaowangzi-2        125        273          1          1      0.995       0.98\n",
      "           qinningshui         96        325          1      0.997      0.995       0.99\n",
      "     quchenshixiangcao         98        254      0.999          1      0.995      0.986\n",
      "              rancha-1         72        178          1          1      0.995      0.983\n",
      "              rancha-2         63        141      0.999      0.993      0.995      0.987\n",
      "           rousongbing         71        101      0.999          1      0.995      0.994\n",
      "       rusuanjunqishui         71        114      0.998          1      0.995      0.988\n",
      "             suanlafen        114        284          1          1      0.995      0.995\n",
      "          suanlaniurou         43         98      0.999          1      0.995      0.994\n",
      "          taipingshuda         43        111          1      0.992      0.995      0.964\n",
      "             tangdaren         62        131      0.999          1      0.995       0.99\n",
      "            tangdaren2         51        103          1          1      0.995      0.995\n",
      "            tangdaren3         38         72      0.998          1      0.995      0.991\n",
      "                   ufo         19         45      0.994          1      0.995      0.977\n",
      "                  ufo2         21         49      0.998          1      0.995      0.995\n",
      "             wanglaoji        125        208      0.999          1      0.995      0.986\n",
      "           wanglaoji-c         69        122      0.996          1      0.995      0.982\n",
      "         wangzainiunai         80        273      0.999          1      0.995      0.985\n",
      "                  weic        149        418          1          1      0.995      0.993\n",
      "              weitanai        105        310          1          1      0.995      0.982\n",
      "             weitanai2        111        228      0.999          1      0.995      0.987\n",
      "        weitanaiditang         80        113          1          1      0.995      0.987\n",
      "         weitaningmeng         86        272      0.999          1      0.995      0.978\n",
      "  weitaningmeng-bottle         66        174      0.999          1      0.995      0.992\n",
      "          weiweidounai        112        278      0.993       0.99      0.995      0.981\n",
      "           wuhounaicha         49         94      0.999          1      0.995      0.982\n",
      "             wulongcha        152        580      0.998          1      0.995      0.984\n",
      "         xianglaniurou         16         32      0.996          1      0.995      0.995\n",
      "            xianguolao         59        101      0.999          1      0.995      0.983\n",
      "          xianxiayuban         43        106      0.999          1      0.995      0.993\n",
      "                 xuebi          2          2      0.944          1      0.995      0.995\n",
      "               xuebi-b         67        146          1          1      0.995      0.977\n",
      "                xuebi2        152        392          1      0.997      0.995      0.991\n",
      "                 yezhi        109        211          1          1      0.995      0.978\n",
      "                 yibao         40         63       0.99      0.984      0.995       0.97\n",
      "                  yida         41         61      0.998          1      0.995      0.986\n",
      "      yingyangkuaixian         26         99      0.999          1      0.995       0.99\n",
      "            yitengyuan         62        122      0.999          1      0.995       0.98\n",
      "              youlemei         75        153      0.998          1      0.995      0.989\n",
      "             yousuanru         68        151          1      0.965      0.995      0.994\n",
      "         youyanggudong         72        114      0.999          1      0.995      0.988\n",
      "            yuanqishui        151        389          1          1      0.995      0.989\n",
      "          zaocanmofang         27         39      0.999          1      0.995      0.938\n",
      "              zihaiguo         15         29      0.996          1      0.995      0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n",
      "/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n",
      "  xa[xa < 0] = -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 0.1ms preprocess, 24.0ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1m/kaggle/working/yolo_finetuned\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# STEP 2: FINETUNING THE MODEL\n",
    "\n",
    "model = YOLO(\"./best.pt\")\n",
    "results = model.train(\n",
    "    data=data_yaml_path,\n",
    "    epochs=5,\n",
    "    imgsz=640,\n",
    "    batch=8,\n",
    "    device=device,\n",
    "    workers=2,\n",
    "    project=\"/kaggle/working/\",\n",
    "    name=\"yolo_finetuned\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T06:19:15.315167Z",
     "iopub.status.busy": "2025-04-26T06:19:15.314836Z",
     "iopub.status.idle": "2025-04-26T06:19:50.480613Z",
     "shell.execute_reply": "2025-04-26T06:19:50.479883Z",
     "shell.execute_reply.started": "2025-04-26T06:19:15.315145Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 542/542 [00:34<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final submission saved to /kaggle/working/submission10.csv\n"
     ]
    }
   ],
   "source": [
    "## STEP 3: INFERENCE ON TEST DATASET\n",
    "\n",
    "test_images = sorted(glob(f\"{image_root}/Test/JPEGImages/*.jpg\"))\n",
    "conf_threshold = 0.4\n",
    "iou_threshold = 0.4\n",
    "final_model = YOLO(\"/kaggle/working/yolo_finetuned/weights/best.pt\")\n",
    "\n",
    "submission_data = []\n",
    "\n",
    "for img_path in tqdm(test_images):\n",
    "    result = final_model.predict(\n",
    "        source=img_path,\n",
    "        conf=conf_threshold,\n",
    "        iou=iou_threshold,\n",
    "        device=device,  # ✅ GPU if available\n",
    "        verbose=False\n",
    "    )[0]\n",
    "\n",
    "    image_id = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    prediction_string = \"\"\n",
    "\n",
    "    for box in result.boxes:\n",
    "        cls_id = int(box.cls.item())\n",
    "        score = box.conf.item()\n",
    "        x1, y1, x2, y2 = box.xyxy[0].tolist()\n",
    "        prediction_string += f\"{id2class[cls_id]} {score:.4f} {int(x1)} {int(y1)} {int(x2)} {int(y2)} \"\n",
    "\n",
    "    submission_data.append({\n",
    "        \"image_id\": image_id,\n",
    "        \"prediction_string\": prediction_string.strip()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T06:23:01.225801Z",
     "iopub.status.busy": "2025-04-26T06:23:01.224929Z",
     "iopub.status.idle": "2025-04-26T06:23:01.240824Z",
     "shell.execute_reply": "2025-04-26T06:23:01.240123Z",
     "shell.execute_reply.started": "2025-04-26T06:23:01.225761Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>prediction_string</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XYG2020121711403780263182_81</td>\n",
       "      <td>damaicha 0.9782 540 109 631 194 damaicha 0.976...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XYG2020121811045959626219_81</td>\n",
       "      <td>youlemei 0.9773 286 151 367 227 hongniu2 0.977...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XYG2020121812002586066796_81</td>\n",
       "      <td>baicha 0.9797 299 120 401 225 moliqingcha 0.97...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XYG2020122214431356849310_81</td>\n",
       "      <td>yida 0.9795 454 431 513 489 damaicha 0.9790 65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XYG2020122214522128735418_81</td>\n",
       "      <td>yida 0.9765 440 313 504 374 baishikele-2 0.976...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image_id  \\\n",
       "0  XYG2020121711403780263182_81   \n",
       "1  XYG2020121811045959626219_81   \n",
       "2  XYG2020121812002586066796_81   \n",
       "3  XYG2020122214431356849310_81   \n",
       "4  XYG2020122214522128735418_81   \n",
       "\n",
       "                                   prediction_string  \n",
       "0  damaicha 0.9782 540 109 631 194 damaicha 0.976...  \n",
       "1  youlemei 0.9773 286 151 367 227 hongniu2 0.977...  \n",
       "2  baicha 0.9797 299 120 401 225 moliqingcha 0.97...  \n",
       "3  yida 0.9795 454 431 513 489 damaicha 0.9790 65...  \n",
       "4  yida 0.9765 440 313 504 374 baishikele-2 0.976...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## STEP 4: SUBMISSION FILE\n",
    "\n",
    "submission_df = pd.DataFrame(submission_data)\n",
    "submission_df.to_csv(\"./output/submission.csv\", index=False)\n",
    "submission_df.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 12005280,
     "sourceId": 100143,
     "sourceType": "competition"
    },
    {
     "datasetId": 7248633,
     "sourceId": 11560616,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 318054,
     "modelInstanceId": 297448,
     "sourceId": 356819,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "wireless",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
